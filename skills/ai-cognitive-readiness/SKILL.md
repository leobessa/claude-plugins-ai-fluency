---
name: ai-cognitive-readiness
description: "Develop pre-fluency cognitive habits: recognize when not to use AI, separate thinking from generation, resist automation bias and output authority."
version: "1.0.0"
---

# Overview

**AI Cognitive Readiness** is Layer 0 of AI fluency—the foundational mindset that must exist *before* learning leverage. This skill prevents misuse by establishing critical thinking habits that protect judgment from AI's persuasive confidence.

**Core Principle:** The most important AI fluency skill is knowing when *not* to use AI.

**Fluency Signal:** Can explain *why* AI should or should not be used for a specific task.

---

## When to Use This Skill

- Before delegating any task to AI, to assess appropriateness
- When noticing automatic reliance on AI for thinking
- When AI output feels "right" but hasn't been verified
- When training others on responsible AI use
- When designing AI-assisted workflows

---

## Core Capabilities

### 1. Recognize When NOT to Use AI

AI is inappropriate when:

- **Accountability matters**: Legal, medical, financial decisions requiring human responsibility
- **Ground truth is critical**: Facts must be verified, not generated
- **Judgment is the deliverable**: The thinking IS the work, not just the output
- **Stakes exceed AI reliability**: Errors are costly or irreversible
- **Context is private**: Data shouldn't leave your control

**Decision Rule:** If you can't verify the output or own the consequences, don't delegate.

### 2. Separate Thinking from Typing

**Anti-pattern:** Using AI to avoid thinking rather than amplify it.

**Practice:**
1. Articulate the problem manually first
2. Define what "good" looks like before asking AI
3. Write your own first draft or outline
4. Use AI to extend, challenge, or refine—not replace

**Test:** "What would I do without AI?" If the answer is "I don't know," stop and think first.

### 3. Resist Automation Bias

**Automation bias**: The tendency to favor AI-generated output over contradictory human judgment.

**Warning signs:**
- Accepting output because it's well-written
- Deferring to AI when uncertain
- Feeling the need to justify disagreement with AI
- Assuming longer/detailed output = better quality

**Corrective practice:**
- Treat every AI output as a hypothesis
- Require evidence before acceptance
- Practice rejection—find reasons output is wrong

### 4. Resist Output Authority Bias

**Output authority**: Mistaking confident, fluent language for accuracy.

**The trap:** AI produces grammatically perfect, structurally sound output that *sounds* authoritative regardless of truthfulness.

**Defense mechanisms:**
- Check claims against external sources
- Ask: "What would make this wrong?"
- Look for hedging that should exist but doesn't
- Verify specific facts, numbers, citations

---

## Practices

### Manual-First Problem Articulation

Before any AI interaction:

1. Write the problem statement in your own words
2. List what you already know
3. Identify what you need (not what you want AI to do)
4. Define success criteria
5. Then—and only then—consider if AI helps

### "What Would I Do Without AI?" Check

For every AI delegation, ask:
- Could I solve this myself? (If no, should you be delegating?)
- What would my approach be? (Frame before delegating)
- What would I check? (Know verification criteria)
- How long would it take? (Is AI actually saving time?)

### Output Skepticism Drills

Regularly practice:
1. Ask AI a question you know the answer to
2. Deliberately introduce errors and see if AI catches them
3. Request output on topics you're expert in—identify hallucinations
4. Compare AI output to authoritative sources

---

## Assessment Criteria

**Layer 0 Complete When:**
- [ ] Can articulate criteria for when AI should NOT be used
- [ ] Consistently frames problems before delegating
- [ ] Questions AI output by default (skepticism as habit)
- [ ] Can identify output authority bias in others
- [ ] Has rejected AI output with documented reasoning

---

## Common Mistakes

### Mistake 1: "AI Is Always Faster"

**Reality:** AI is faster at generation. But:
- Verification takes time
- Iteration takes time
- Fixing AI errors takes time

For many tasks, doing it yourself is faster end-to-end.

### Mistake 2: "I'll Just Check It Later"

**Reality:** Checking AI output requires the same expertise as creating it. If you can't thoroughly verify, you can't safely delegate.

### Mistake 3: "AI Is Just a Tool"

**Reality:** AI actively shapes your thinking. It biases toward certain framings, formats, and conclusions. Awareness of this influence is part of cognitive readiness.

---

## Related Skills

- [ai-system-literacy](../ai-system-literacy/SKILL.md) — Next layer: understanding how AI actually behaves
- [ai-evaluation-verification](../ai-evaluation-verification/SKILL.md) — Deep dive on verification practices
- [ai-fluency-antipatterns](../ai-fluency-antipatterns/SKILL.md) — Common traps this layer prevents

---

## Learn More

- [Pre-Fluency Assessment Checklist](references/assessment-checklist.md)
- [Output Skepticism Exercises](references/skepticism-exercises.md)
